<!DOCTYPE html>
<!-- saved from url=(0030)https://denghilbert.github.io/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zhehao Zhang's Homepageüåü</title>
  
  <meta name="author" content="Zhehao Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="keywords" content="Zhehao, Zhehao Zhang, Dartmouth College, Dartmouth, SJTU, zhehao zhang, sjtu, Dartmouth, Shanghai Jiao Tong University">
  <link rel="stylesheet" type="text/css" href="./stylesheet.css">
	<link rel="icon" href="./images/logo.png">
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-25H6S86264"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-25H6S86264');
</script></head>

<!-- Google tag (gtag.js) -->
<!---->

	
<body>
  <table style="width:100%;max-width:1100px;border:0px;border-spacing:0;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:collapse;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:70%;vertical-align:middle">
              <p style="text-align:center">
                <name>Zhehao Zhang</name>
              </p>
              <p> I am a first year Master student in <a href="https://web.cs.dartmouth.edu/">Computer Science</a> at <a href="https://home.dartmouth.edu/">Dartmouth College</a>. Currently, I am a research intern at <a href="https://saltlab.stanford.edu/">Stanford SALT Lab</a> under the supervision of <a href="https://cs.stanford.edu/~diyiy/index.html">Diyi Yang</a>. Previously, I worked as a Research Intern at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/">Microsoft Research Lab ‚Äì Asia</a>. I received my bachelor's degree in <a href="https://zsb.sjtu.edu.cn/web/jdzsb/3810055-3810000002464.htm">Artificial Intelligence Honor Class</a> at <a href="https://en.sjtu.edu.cn/">Shanghai Jiao Tong University</a>.
              </p>

              <p>
		      My research interests lie in Natural Language Processing (NLP).
              </p>
              <p> Please feel free to contact me by email!</p>
              

              
              <p style="text-align:center">
				<!-- <a href="mailto:yd428@cornell.edu">Email</a> &nbsp;/&nbsp; -->
              	<a href="mailto:zhehao.zhang.gr@dartmouth.edu">Mail</a> &nbsp;/&nbsp;
                <a href="./images/CV_zhehao_2024_8.pdf">R√©sum√©</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=QG-BAGwAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://github.com/zzh-SJTU">Github</a>&nbsp;
              </p>

              
            </td>
            <td style="padding:2.5%;width:30%;max-width:40%">
              <a href="./images/zhehao.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="./images/zhehao.jpg" class="hoverZoomLink"></a>
            	<!-- <p></p><details close=""><summary>Credits</summary> -->
             	<!-- <p>This set of photometric stereo images is inspired by Prof. David Kriegman.</p></details><p></p> -->
            </td>
          </tr>
        </tbody></table>
	      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Newsüì¢</heading>
              <p>
			<ul>  
			<li>2024 June 25th: A new preprint is released! Please check <a href="https://arxiv.org/abs/2406.17271">DARG</a> which is a dynamic evaluation framework aiming to augment current reasoning benchmarks from the level of reasoning graphs.</li>
			<li>2024 Mar 13th: One first-author paper on LLMs for hierarchical table analysis is accepted to <a href="https://2024.naacl.org/">NAACL 2024</a>. See you in Mexico City!</li>
			<li>2024 Mar: Honored to give a talk on Augmented Language Models at TRIP Lab at Dartmouth, hosted by Prof. Yaoqing Yang. <a href="https://youtu.be/FhAZWa1KvFA">Recording</a> and the <a href="https://docs.google.com/presentation/d/1-_XNiQsh07oEnU5nXV_ysgtM0HvJHk-1tyVKEzmiXkg/edit?usp=sharing">slide</a> are available.</li>
			<li>2024 Feb: I will join  <a href="https://research.adobe.com/">Adobe Research</a> as Research Intern in this summer. See you in San Jose and bay area!</li>
			<li>2023 Dec 14th: One first-author papers from my undergraduate is accepted to <a href="https://2024.ieeeicassp.org/">ICASSP 2024</a>.</li>
			  <li>2023 Oct 27th: The paper titled "Can Large Language Models Transform Computational Social Science?" is accepted to <a href="https://direct.mit.edu/coli">Computational Linguistics</a>.</li>
            		<li>2023 Oct 7th: Two first-author papers from my undergraduate are accepted to <a href="https://2023.emnlp.org/">EMNLP 2023</a>. See you in Singapore!</li>
			</ul>  
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Researchüîç </heading>
              <p>
		      My current research interests lie in multiple fields in NLP including:
			<ul>  
			  <li>Tool-augmented LLMs</li>  
			  <li>Dynamic evaluation of LLMs</li> 
			  <li>Computational social science (NLP for social good)</li>  
			  <li>LLM-based agents</li>  
			  <li>Vison-Language Models</li> 
			</ul>  
                I also have a broad interest in other topics in NLP and Machine Learning.
              </p>
            </td>
          </tr>
        </tbody></table>
		
        <table style="width:100%;border:0;border-collapse:collapse;border-spacing:0;margin-right:auto;margin-left:auto;"><tbody>
		            <tr style="vertical-align:left;">
			    <td style="padding:3px;width:50%;vertical-align:center">
				  <img src="./images/framework.png" width="600">
			    </td>
			  <td style="padding:10px;width:75%;vertical-align:center">
				  <papertitle>DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph</papertitle>
				</a>
				<br>
				<strong>Zhehao Zhang</strong>,
				<a href="https://sites.cc.gatech.edu/~jchen896/">Jiaao Chen</a>,
				<a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>
				<br>
				<em>Arxiv Pre-print</em>, 2024
				<br>
				<a href="https://github.com/SALT-NLP/DARG">Code</a>
				/
				<a href="https://salt-nlp.github.io/DARG_website/">Project</a>
				/
				<a href="https://arxiv.org/abs/2406.17271">Paper</a>
				<p></p>
				<p>
				TL; DR: We propose a dynamic evaluation framework named DARG, aimed at augmenting current reasoning benchmarks from the level of reasoning graphs. We evaluate 15 SOTA LLMs and observe a consistent performance decrease for all LLMs as the complexity level increases, along with increasing biases on some datasets.
				</p>
				<!-- <p>Thanks to my mentors and advisor for their support!</p> -->
			  </td>
			</tr>	
			    <tr style="vertical-align:left;">
			    <td style="padding:3px;width:50%;vertical-align:center">
				  <img src="./images/e5.png" width="600">
			    </td>
			  <td style="padding:10px;width:75%;vertical-align:center">
				  <papertitle>E5: Zero-shot Hierarchical Table Analysis using Augmented LLMs via Explain, Extract, Execute, Exhibit, and Extrapolate</papertitle>
				</a>
				<br>
				<strong>Zhehao Zhang</strong>,
				<a href="https://www.microsoft.com/en-us/research/people/gaoya/">Yan Gao</a>
				<a href="https://www.microsoft.com/en-us/research/people/jlou/">Jian-Guang Lou</a>
				<br>
				<em>Proceedings of the 2024 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)</em>, 2024
				<br>
				<a href="https://github.com/zzh-SJTU/E5-Hierarchical-Table-Analysis">Code</a>
				/
				<a href="https://aclanthology.org/2024.naacl-long.68/">Paper</a>
				<p></p>
				<p>
				TL; DR: We propose a tool-augmented LLM framework named $E^5$ that contains 5 stages to solve the challenging real-life hierarchical table analysis task which achieves an 85.08 exact match score and 93.11 GPT-4-Eval Score. We also introduce $F^3$ which significantly reduces the token length while maintaining useful information to analyze such huge tables. 
				<!-- <p>Thanks to my mentors and advisor for their support!</p> -->
			  </td>
			</tr>
		<tr style="vertical-align:left;">
			    <td style="padding:3px;width:50%;vertical-align:center">
				  <img src="./images/CRT.png" width="600">
			    </td>
			  <td style="padding:10px;width:75%;vertical-align:center">
				  <papertitle>CRT-QA: A Dataset of Complex Reasoning Question Answering over Tabular Data</papertitle>
				</a>
				<br>
				<strong>Zhehao Zhang</strong>,
				<a>Xitao Li</a>,
				<a href="https://www.microsoft.com/en-us/research/people/gaoya/">Yan Gao</a>
				<a href="https://www.microsoft.com/en-us/research/people/jlou/">Jian-Guang Lou</a>
				<br>
				<em>Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2023
				<br>
				<a href="https://github.com/zzh-SJTU/CRT-QA">Code</a>
				/
				<a href="https://aclanthology.org/2023.emnlp-main.132/">Paper</a>
				<p></p>
				<p>
				TL; DR: We systematically evaluate LLMs' reasoning ability on tabular data and establish a comprehensive taxonomy on operation and reasoning types for table analysis. hen, we propose CRT-QA, a dataset of complex reasoning QA over tables. We propose ARC which effectively utilizes table analysis tools to solve table reasoning tasks without manually-annotated exemplars.
				</p>
				<!-- <p>Thanks to my mentors and advisor for their support!</p> -->
			  </td>
			</tr>
			    <tr style="vertical-align:left;">
			    <td style="padding:3px;width:50%;vertical-align:center">
				  <img src="./images/hate.png" width="600">
			    </td>
			  <td style="padding:10px;width:75%;vertical-align:center">
				  <papertitle>Mitigating Biases in Hate Speech Detection from A Causal Perspective</papertitle>
				</a>
				<br>
				<strong>Zhehao Zhang</strong>,
				<a href="https://sites.cc.gatech.edu/~jchen896/">Jiaao Chen</a>,
				<a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>
				<br>
				<em>Findings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2023
				<br>
				<a href="https://github.com/SALT-NLP/Bias_Hate_Causal">Code</a>
				/
				<a href="https://aclanthology.org/2023.findings-emnlp.440.pdf">Paper</a>
				<p></p>
				<p>
				TL; DR: We analyze the generation process of HS biases from a causal view and identify two confounders that cause the biases. Propose Multi-Task Intervention and Data-Specific Intervention to mitigate them.
				</p>
				<!-- <p>Thanks to my mentors and advisor for their support!</p> -->
			  </td>
			</tr>	
			  <tr style="vertical-align:left;">
			    <td style="padding:3px;width:50%;vertical-align:center">
				  <img src="./images/css.png" width="600">
			    </td>
			  <td style="padding:10px;width:75%;vertical-align:center">
				<a href="https://arxiv.org/abs/2305.03514">
				  <papertitle>Can Large Language Models Transform Computational Social Science?</papertitle>
				</a>
				<br>
				<a href="https://calebziems.com/">Caleb Ziems</a>,
				<a href="https://williamheld.com/">William Held</a>,
				<a href="http://oshaikh.com/">Omar Shaikh</a>,
				<a href="https://sites.cc.gatech.edu/~jchen896/">Jiaao Chen</a>,
				<strong>Zhehao Zhang</strong>,
				<a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>
				<br>
				<em>Computational Linguistics</em>, 2023
				<br>
				<a href="https://github.com/SALT-NLP/LLMs_for_CSS">Code</a>
				/
				<a href="https://direct.mit.edu/coli/article/50/1/237/118498/Can-Large-Language-Models-Transform-Computational">Paper</a>
				<p></p>
				<p>
				TL; DR: We provide a road map for using LLMs as CSS tools and  contribute a set of prompting best practices and an extensive evaluation pipeline to measure the zero-shot performance of 13 language models on 24 representative CSS benchmarks.
				</p>
				<!-- <p>Thanks to my mentors and advisor for their support!</p> -->
			  </td>
			</tr>

        </tbody></table>
		
		<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
		  <tr>
			<td>
			  <heading>Educationüéì</heading>
			</td>
		  </tr>
		</tbody></table>
		<table width="100%" align="center" border="0" cellpadding="20"><tbody>
			<tr>
				<td style="padding:20px;width:25%;vertical-align:middle"><img width="100" src="./images/dartmouth.png"></td>
				<td width="75%" valign="center">
				  <p> Dartmouth College, Master of Science in Computer Science, 2023 - 2025 (expected) </p>
				</td>
			</tr>
			<tr>
				<td style="padding:20px;width:25%;vertical-align:middle"><img width="100" src="./images/sjtu.png"></td>
				<td width="75%" valign="center">
				  <p>Shanghai Jiao Tong University, B.Eng. in Artificial Intelligence (Honor Class), 2019 - 2023 </p>
				</td>
			</tr>	
		</tbody></table>
		
		<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
		  <tr>
			<td>
			  <heading>Experiencesüõ†</heading>
			</td>
		  </tr>
		</tbody></table>
		<table width="100%" align="center" border="0" cellpadding="20"><tbody>
			<tr>
				<td style="padding:20px;width:25%;vertical-align:middle"><img width="100" src="./images/stanford.png"></td>
				<td width="75%" valign="center">
				  <p><a href="https://saltlab.stanford.edu/people/">Social and Language Technologies (SALT) lab at Stanford</a>, Research Intern </p>
				</td>
			</tr>
			<tr>
				<td style="padding:20px;width:25%;vertical-align:middle"><img width="100" src="./images/adobe-1-logo.png"></td>
				<td width="75%" valign="center">
				  <p><a href="https://research.adobe.com/">Adobe Research</a>, Research Intern </p>
				</td>
			</tr>
			<tr>
				<td style="padding:20px;width:25%;vertical-align:middle"><img width="100" src="./images/mms.png"></td>
				<td width="75%" valign="center">
				  <p><a href="https://www.microsoft.com/en-us/research/group/data-knowledge-intelligence/">Data, Knowledge, and Intelligence group at Microsoft Research Lab ‚Äì Asia</a>, Research Intern </p>
				</td>
			</tr>

		</tbody></table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
		</tbody></table>
		<table width="100%" align="center" border="0" cellpadding="20"><tbody>  
				   <p></p><details close=""><summary>Selected Courses</summary>
             	<p>AI courses: Natural language processing (94 points), Deep learning and application (92.95 points), Computer vision, Reinforcement learning (94 points), Machine learning, Machine learning project, Knowledge representation and reasoning (97 points), A practical course to intelligence perception and cognition (90 points), Brain-Inspired Intelligence (92 points), Artificial intelligence problem solving and practice (95 points), Intelligent speech recognition (92 points), Data mining (91 points), Game theory and multi-agent learning, Programming practices of artificial intelligence, Lab practice (A+)<p></p>
		<p>Other CS courses: Data structure(Honor)(92 points), Thinking and approach of programming (C++)(Honor), Data structure (C++)(Honor), Design and analysis of algorithms, Computer architecture(91 points), Operating system(91 points), Internet of thing(95.5 points)</p><p></p>
		<p>Math courses: Stochastic process (95 points), Mathematical analysis(Honor), Linear algebra(Honor), Discrete mathematics(Honor), Complex analysis(Honor), Probability and Statistics, Convex and linear optimization, Signals and Systems, Digital signal and image processing</p></details><p></p>
			</td>
		</tr></tbody></table>
			  
        <table class="center" style="border:0px;border-spacing:0px;border-collapse:separate;">  
  <tbody>  
    <tr>  
      <td style="padding:0px">  
        <br>  
        <p style="text-align:right;font-size:small;">  
          Website template borrowed from Jon Barron's personal page <a href="https://jonbarron.info/">Here</a>  
        </p>  
      </td>  
    </tr>  
  </tbody>  
</table>  



</body></html>
